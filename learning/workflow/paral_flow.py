# å¹¶è¡Œå·¥ä½œæµç¨‹ç¤ºä¾‹ - ä½¿ç”¨LangGraphæ„å»ºå¹¶è¡Œæ‰§è¡Œçš„å†…å®¹ç”Ÿæˆå™¨
# åŠŸèƒ½ï¼šæ ¹æ®ç»™å®šä¸»é¢˜ï¼Œå¹¶è¡Œç”Ÿæˆç¬‘è¯ã€æ•…äº‹å’Œè¯—æ­Œï¼Œæœ€ååˆå¹¶è¾“å‡º

import os
import getpass
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END
from IPython.display import Image, display
from dotenv import load_dotenv
from langchain_qwq import ChatQwQ

# åŠ è½½ç¯å¢ƒå˜é‡é…ç½®
load_dotenv()

# åˆå§‹åŒ–é€šä¹‰åƒé—®LLMæ¨¡å‹
llm = ChatQwQ(
    model="qwen3-8b",                                                    # ä½¿ç”¨qwen3-8bæ¨¡å‹
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",      # é˜¿é‡Œäº‘APIåœ°å€
    max_tokens=3_000,                                                   # æœ€å¤§ç”Ÿæˆtokenæ•°
    timeout=None,                                                       # è¶…æ—¶è®¾ç½®
    max_retries=2,                                                      # æœ€å¤§é‡è¯•æ¬¡æ•°
    # other params...
)

# æ£€æŸ¥å¹¶è®¾ç½®APIå¯†é’¥
if not os.getenv("DASHSCOPE_API_KEY"):
    os.environ["DASHSCOPE_API_KEY"] = getpass.getpass("Enter your Dashscope API key: ")

# å›¾çŠ¶æ€å®šä¹‰ - å®šä¹‰å·¥ä½œæµä¸­ä¼ é€’çš„æ•°æ®ç»“æ„
class State(TypedDict):
    topic: str          # è¾“å…¥ä¸»é¢˜
    joke: str           # ç”Ÿæˆçš„ç¬‘è¯
    story: str          # ç”Ÿæˆçš„æ•…äº‹
    poem: str           # ç”Ÿæˆçš„è¯—æ­Œ
    combined_output: str # åˆå¹¶åçš„æœ€ç»ˆè¾“å‡º

# èŠ‚ç‚¹å‡½æ•°å®šä¹‰ - æ¯ä¸ªèŠ‚ç‚¹è´Ÿè´£ç‰¹å®šçš„å¤„ç†ä»»åŠ¡

def call_llm_1(state: State):
    """ç¬¬ä¸€ä¸ªLLMè°ƒç”¨ - ç”Ÿæˆç¬‘è¯"""
    msg = llm.invoke(f"Write a joke about {state['topic']}")
    return {"joke": msg.content}

def call_llm_2(state: State):
    """ç¬¬äºŒä¸ªLLMè°ƒç”¨ - ç”Ÿæˆæ•…äº‹"""
    msg = llm.invoke(f"Write a story about {state['topic']}")
    return {"story": msg.content}

def call_llm_3(state: State):
    """ç¬¬ä¸‰ä¸ªLLMè°ƒç”¨ - ç”Ÿæˆè¯—æ­Œ"""
    msg = llm.invoke(f"Write a poem about {state['topic']}")
    return {"poem": msg.content}

def aggregator(state: State):
    """èšåˆå™¨ - å°†ç¬‘è¯ã€æ•…äº‹å’Œè¯—æ­Œåˆå¹¶ä¸ºå•ä¸ªè¾“å‡º"""
    combined = f"Here's a story, joke, and poem about {state['topic']}!\n\n"
    combined += f"STORY:\n{state['story']}\n\n"
    combined += f"JOKE:\n{state['joke']}\n\n"
    combined += f"POEM:\n{state['poem']}"
    return {"combined_output": combined}

# æ„å»ºå·¥ä½œæµç¨‹å›¾
parallel_builder = StateGraph(State)

# æ·»åŠ èŠ‚ç‚¹åˆ°å›¾ä¸­
parallel_builder.add_node("call_llm_1", call_llm_1)  # ç¬‘è¯ç”ŸæˆèŠ‚ç‚¹
parallel_builder.add_node("call_llm_2", call_llm_2)  # æ•…äº‹ç”ŸæˆèŠ‚ç‚¹
parallel_builder.add_node("call_llm_3", call_llm_3)  # è¯—æ­Œç”ŸæˆèŠ‚ç‚¹
parallel_builder.add_node("aggregator", aggregator)   # èšåˆèŠ‚ç‚¹

# æ·»åŠ è¾¹è¿æ¥èŠ‚ç‚¹ - å®šä¹‰æ‰§è¡Œæµç¨‹
# ä»STARTå¼€å§‹ï¼Œä¸‰ä¸ªLLMè°ƒç”¨å¹¶è¡Œæ‰§è¡Œ
parallel_builder.add_edge(START, "call_llm_1")
parallel_builder.add_edge(START, "call_llm_2")
parallel_builder.add_edge(START, "call_llm_3")

# ä¸‰ä¸ªLLMè°ƒç”¨çš„ç»“æœéƒ½æ±‡èšåˆ°èšåˆå™¨
parallel_builder.add_edge("call_llm_1", "aggregator")
parallel_builder.add_edge("call_llm_2", "aggregator")
parallel_builder.add_edge("call_llm_3", "aggregator")

# èšåˆå™¨å¤„ç†å®Œåç»“æŸ
parallel_builder.add_edge("aggregator", END)

# ç¼–è¯‘å·¥ä½œæµ
parallel_workflow = parallel_builder.compile()

def stream_graph_updates(user_input: str):
    """
    ç®€å•çš„LLMè°ƒç”¨ - ç›´æ¥ä¸ç”¨æˆ·å¯¹è¯
    å‚æ•°: user_input - ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
    """
    # ç›´æ¥è°ƒç”¨LLMè¿›è¡Œå¯¹è¯
    response = llm.invoke(user_input)
    print("Assistant:", response.content)

def demo_parallel_workflow():
    """æ¼”ç¤ºå¹¶è¡Œå·¥ä½œæµç¨‹ - ç”Ÿæˆç¬‘è¯ã€æ•…äº‹å’Œè¯—æ­Œ"""
    print("=== å¹¶è¡Œå·¥ä½œæµç¨‹æ¼”ç¤º ===")
    print("æ­£åœ¨æ˜¾ç¤ºå·¥ä½œæµå›¾å½¢...")

    # æ˜¾ç¤ºå·¥ä½œæµå›¾å½¢
    try:
        display(Image(parallel_workflow.get_graph().draw_mermaid_png()))
    except Exception as e:
        print(f"æ— æ³•æ˜¾ç¤ºå›¾å½¢: {e}")

    # è·å–ç”¨æˆ·è¾“å…¥çš„ä¸»é¢˜
    topic = input("\nè¯·è¾“å…¥ä¸€ä¸ªä¸»é¢˜æ¥ç”Ÿæˆå†…å®¹ (æˆ–ç›´æ¥æŒ‰å›è½¦ä½¿ç”¨é»˜è®¤ä¸»é¢˜'cats'): ").strip()
    if not topic:
        topic = "cats"

    # æ‰§è¡Œå·¥ä½œæµ
    print(f"\næ­£åœ¨ç”Ÿæˆå…³äº'{topic}'çš„å†…å®¹...")
    state = parallel_workflow.invoke({"topic": topic})
    print("\nç”Ÿæˆç»“æœ:")
    print(state["combined_output"])

def interactive_chat():
    """äº¤äº’å¼èŠå¤©åŠŸèƒ½"""
    print("\n=== äº¤äº’å¼èŠå¤©æ¨¡å¼ ===")
    print("è¾“å…¥ 'quit', 'exit' æˆ– 'q' é€€å‡ºèŠå¤©")
    print("-" * 50)

    while True:
        user_input = input("User: ")
        if user_input.lower() in ["quit", "exit", "q"]:
            print("Goodbye! å†è§!")
            break
        stream_graph_updates(user_input)
        print()

def main():
    """ä¸»å‡½æ•° - æä¾›å¤šç§åŠŸèƒ½é€‰æ‹©"""
    print("ğŸš€ LangGraph å¹¶è¡Œå·¥ä½œæµç¨‹å’ŒèŠå¤©ç³»ç»Ÿ")
    print("=" * 50)

    while True:
        print("\nè¯·é€‰æ‹©åŠŸèƒ½:")
        print("1. æ¼”ç¤ºå¹¶è¡Œå·¥ä½œæµç¨‹ (ç”Ÿæˆç¬‘è¯ã€æ•…äº‹ã€è¯—æ­Œ)")
        print("2. äº¤äº’å¼èŠå¤©")
        print("3. é€€å‡º")

        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()

        if choice == "1":
            demo_parallel_workflow()
        elif choice == "2":
            interactive_chat()
        elif choice == "3":
            print("æ„Ÿè°¢ä½¿ç”¨! å†è§!")
            break
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1ã€2 æˆ– 3")

if __name__ == "__main__":
    main()
