# ç¼–æ’å·¥ä½œæµç¨‹ç¤ºä¾‹ - ä½¿ç”¨LangGraphæ„å»ºå¤šå·¥ä½œè€…åä½œçš„æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ
# åŠŸèƒ½ï¼šè‡ªåŠ¨ç”ŸæˆæŠ¥å‘Šè®¡åˆ’ï¼Œå¹¶è¡Œç¼–å†™å„ä¸ªç« èŠ‚ï¼Œæœ€ååˆæˆå®Œæ•´æŠ¥å‘Š

import os
import getpass
import operator
from typing_extensions import TypedDict, Annotated
from langgraph.graph import StateGraph, START, END
from langgraph.constants import Send
from IPython.display import Image, display, Markdown
from dotenv import load_dotenv
from langchain_qwq import ChatQwQ
from pydantic import BaseModel, Field
from langchain_core.messages import HumanMessage, SystemMessage

# åŠ è½½ç¯å¢ƒå˜é‡é…ç½®
load_dotenv()

# åˆå§‹åŒ–é€šä¹‰åƒé—®LLMæ¨¡å‹
llm = ChatQwQ(
    model="qwen3-4b",                                                    # ä½¿ç”¨qwen3-4bæ¨¡å‹
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",      # é˜¿é‡Œäº‘APIåœ°å€
    max_tokens=3_000,                                                   # æœ€å¤§ç”Ÿæˆtokenæ•°
    timeout=None,                                                       # è¶…æ—¶è®¾ç½®
    max_retries=2,                                                      # æœ€å¤§é‡è¯•æ¬¡æ•°
    # other params...
)

# æ£€æŸ¥å¹¶è®¾ç½®APIå¯†é’¥
if not os.getenv("DASHSCOPE_API_KEY"):
    os.environ["DASHSCOPE_API_KEY"] = getpass.getpass("Enter your Dashscope API key: ")

# æŠ¥å‘Šç« èŠ‚ç»“æ„å®šä¹‰
class Section(BaseModel):
    name: str = Field(description="ç« èŠ‚åç§°")
    description: str = Field(description="ç« èŠ‚æè¿°å’Œè¦æ±‚")

# æŠ¥å‘Šè®¡åˆ’ç»“æ„å®šä¹‰
class Plan(BaseModel):
    sections: list[Section] = Field(description="æŠ¥å‘Šç« èŠ‚åˆ—è¡¨")

# å¢å¼ºLLMä»¥æ”¯æŒç»“æ„åŒ–è¾“å‡ºï¼Œç”¨äºæŠ¥å‘Šè§„åˆ’
planner = llm.with_structured_output(Plan)

# ä¸»çŠ¶æ€å®šä¹‰ - åœ¨æ•´ä¸ªå·¥ä½œæµä¸­ä¼ é€’çš„æ•°æ®ç»“æ„
class State(TypedDict):
    topic: str                                      # æŠ¥å‘Šä¸»é¢˜
    sections: list[Section]                         # æŠ¥å‘Šç« èŠ‚åˆ—è¡¨
    completed_sections: Annotated[list, operator.add]  # æ‰€æœ‰å·¥ä½œè€…å¹¶è¡Œå†™å…¥çš„å®Œæˆç« èŠ‚
    final_report: str                               # æœ€ç»ˆæŠ¥å‘Š

# å·¥ä½œè€…çŠ¶æ€å®šä¹‰ - æ¯ä¸ªå·¥ä½œè€…å¤„ç†å•ä¸ªç« èŠ‚æ—¶ä½¿ç”¨çš„çŠ¶æ€
class WorkerState(TypedDict):
    section: Section                                # è¦å¤„ç†çš„ç« èŠ‚
    completed_sections: Annotated[list, operator.add]  # å®Œæˆçš„ç« èŠ‚åˆ—è¡¨

# èŠ‚ç‚¹å‡½æ•°å®šä¹‰ - æ¯ä¸ªèŠ‚ç‚¹è´Ÿè´£ç‰¹å®šçš„å¤„ç†ä»»åŠ¡

def orchestrator(state: State):
    """ç¼–æ’è€…èŠ‚ç‚¹ - ç”ŸæˆæŠ¥å‘Šè®¡åˆ’å¹¶åˆ†è§£ä¸ºå¤šä¸ªç« èŠ‚"""
    # ä½¿ç”¨è§„åˆ’å™¨ç”ŸæˆæŠ¥å‘Šç« èŠ‚
    report_sections = planner.invoke(
        [
            SystemMessage(content="ä¸ºæŠ¥å‘Šç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„è®¡åˆ’ï¼ŒåŒ…æ‹¬å„ä¸ªç« èŠ‚çš„åç§°å’Œæè¿°ã€‚"),
            HumanMessage(content=f"æŠ¥å‘Šä¸»é¢˜æ˜¯: {state['topic']}"),
        ]
    )
    return {"sections": report_sections.sections}

def llm_call(state: WorkerState):
    """å·¥ä½œè€…èŠ‚ç‚¹ - ç¼–å†™æŠ¥å‘Šçš„å•ä¸ªç« èŠ‚"""
    # ç”Ÿæˆç« èŠ‚å†…å®¹
    section = llm.invoke(
        [
            SystemMessage(
                content="æ ¹æ®æä¾›çš„ç« èŠ‚åç§°å’Œæè¿°ç¼–å†™æŠ¥å‘Šç« èŠ‚ã€‚ä¸è¦åŒ…å«ç« èŠ‚å‰è¨€ã€‚ä½¿ç”¨markdownæ ¼å¼ã€‚"
            ),
            HumanMessage(
                content=f"ç« èŠ‚åç§°: {state['section'].name}\nç« èŠ‚æè¿°: {state['section'].description}"
            ),
        ]
    )
    # å°†å®Œæˆçš„ç« èŠ‚å†™å…¥åˆ°å®Œæˆç« èŠ‚åˆ—è¡¨ä¸­
    return {"completed_sections": [section.content]}

def synthesizer(state: State):
    """åˆæˆå™¨èŠ‚ç‚¹ - å°†æ‰€æœ‰å®Œæˆçš„ç« èŠ‚åˆæˆä¸ºå®Œæ•´æŠ¥å‘Š"""
    # è·å–å®Œæˆçš„ç« èŠ‚åˆ—è¡¨
    completed_sections = state["completed_sections"]

    # å°†å®Œæˆçš„ç« èŠ‚æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²ï¼Œç”¨ä½œæœ€ç»ˆæŠ¥å‘Šçš„ä¸Šä¸‹æ–‡
    completed_report_sections = "\n\n---\n\n".join(completed_sections)

    return {"final_report": completed_report_sections}

# æ¡ä»¶è¾¹å‡½æ•° - ä¸ºæ¯ä¸ªç« èŠ‚åˆ›å»ºå·¥ä½œè€…
def assign_workers(state: State):
    """ä¸ºè®¡åˆ’ä¸­çš„æ¯ä¸ªç« èŠ‚åˆ†é…ä¸€ä¸ªå·¥ä½œè€…"""
    # é€šè¿‡Send() APIå¹¶è¡Œå¯åŠ¨ç« èŠ‚ç¼–å†™ä»»åŠ¡
    return [Send("llm_call", {"section": s}) for s in state["sections"]]

# æ„å»ºç¼–æ’å·¥ä½œæµç¨‹å›¾
orchestrator_worker_builder = StateGraph(State)

# æ·»åŠ èŠ‚ç‚¹åˆ°å›¾ä¸­
orchestrator_worker_builder.add_node("orchestrator", orchestrator)    # ç¼–æ’è€…èŠ‚ç‚¹
orchestrator_worker_builder.add_node("llm_call", llm_call)            # å·¥ä½œè€…èŠ‚ç‚¹ï¼ˆå¯å¹¶è¡Œï¼‰
orchestrator_worker_builder.add_node("synthesizer", synthesizer)      # åˆæˆå™¨èŠ‚ç‚¹

# æ·»åŠ è¾¹è¿æ¥èŠ‚ç‚¹ - å®šä¹‰æ‰§è¡Œæµç¨‹
orchestrator_worker_builder.add_edge(START, "orchestrator")           # ä»STARTå¼€å§‹åˆ°ç¼–æ’è€…

# æ·»åŠ æ¡ä»¶è¾¹ - æ ¹æ®ç« èŠ‚æ•°é‡åŠ¨æ€åˆ†é…å·¥ä½œè€…
orchestrator_worker_builder.add_conditional_edges(
    "orchestrator",      # æ¥æºèŠ‚ç‚¹
    assign_workers,      # åˆ†é…å‡½æ•°
    ["llm_call"]         # ç›®æ ‡èŠ‚ç‚¹åˆ—è¡¨
)

orchestrator_worker_builder.add_edge("llm_call", "synthesizer")       # æ‰€æœ‰å·¥ä½œè€…å®Œæˆååˆ°åˆæˆå™¨
orchestrator_worker_builder.add_edge("synthesizer", END)              # åˆæˆå™¨å®Œæˆåç»“æŸ

# ç¼–è¯‘å·¥ä½œæµ
orchestrator_worker = orchestrator_worker_builder.compile()

def simple_llm_chat(user_input: str):
    """
    ç®€å•çš„LLMå¯¹è¯ - ç›´æ¥ä¸ç”¨æˆ·å¯¹è¯
    å‚æ•°: user_input - ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
    """
    response = llm.invoke(user_input)
    print("Assistant:", response.content)

def demo_orchestrator_workflow():
    """æ¼”ç¤ºç¼–æ’å·¥ä½œæµç¨‹ - è‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Š"""
    print("=== ç¼–æ’å·¥ä½œæµç¨‹æ¼”ç¤º ===")
    print("æ­£åœ¨æ˜¾ç¤ºå·¥ä½œæµå›¾å½¢...")

    # æ˜¾ç¤ºå·¥ä½œæµå›¾å½¢
    try:
        display(Image(orchestrator_worker.get_graph().draw_mermaid_png()))
    except Exception as e:
        print(f"æ— æ³•æ˜¾ç¤ºå›¾å½¢: {e}")

    # è·å–ç”¨æˆ·è¾“å…¥çš„æŠ¥å‘Šä¸»é¢˜
    topic = input("\nè¯·è¾“å…¥æŠ¥å‘Šä¸»é¢˜ (æˆ–ç›´æ¥æŒ‰å›è½¦ä½¿ç”¨é»˜è®¤ä¸»é¢˜): ").strip()
    if not topic:
        topic = "Create a report on LLM scaling laws"
        print(f"ä½¿ç”¨é»˜è®¤ä¸»é¢˜: {topic}")

    # æ‰§è¡Œç¼–æ’å·¥ä½œæµ
    print(f"\næ­£åœ¨ç”Ÿæˆå…³äº'{topic}'çš„æŠ¥å‘Š...")
    print("æ­¥éª¤1: ç¼–æ’è€…æ­£åœ¨åˆ¶å®šæŠ¥å‘Šè®¡åˆ’...")
    print("æ­¥éª¤2: å¤šä¸ªå·¥ä½œè€…å¹¶è¡Œç¼–å†™ç« èŠ‚...")
    print("æ­¥éª¤3: åˆæˆå™¨æ­£åœ¨æ•´åˆæœ€ç»ˆæŠ¥å‘Š...")

    state = orchestrator_worker.invoke({"topic": topic})

    print(f"\næŠ¥å‘Šç”Ÿæˆå®Œæˆ! å…±ç”Ÿæˆ {len(state.get('completed_sections', []))} ä¸ªç« èŠ‚")
    print("\n" + "="*60)
    print("æœ€ç»ˆæŠ¥å‘Š:")
    print("="*60)

    # åœ¨æ§åˆ¶å°æ˜¾ç¤ºæŠ¥å‘Šå†…å®¹
    print(state["final_report"])

    # å¦‚æœåœ¨Jupyterç¯å¢ƒä¸­ï¼Œä¹Ÿå¯ä»¥æ˜¾ç¤ºMarkdownæ ¼å¼
    try:
        display(Markdown(state["final_report"]))
    except:
        pass  # éJupyterç¯å¢ƒä¸­å¿½ç•¥

def interactive_chat():
    """äº¤äº’å¼èŠå¤©åŠŸèƒ½"""
    print("\n=== äº¤äº’å¼èŠå¤©æ¨¡å¼ ===")
    print("è¾“å…¥ 'quit', 'exit' æˆ– 'q' é€€å‡ºèŠå¤©")
    print("-" * 50)

    while True:
        user_input = input("User: ")
        if user_input.lower() in ["quit", "exit", "q"]:
            print("Goodbye! å†è§!")
            break
        simple_llm_chat(user_input)
        print()

def interactive_report_generator():
    """äº¤äº’å¼æŠ¥å‘Šç”Ÿæˆå™¨"""
    print("\n=== äº¤äº’å¼æŠ¥å‘Šç”Ÿæˆå™¨ ===")
    print("è¾“å…¥ 'quit', 'exit' æˆ– 'q' é€€å‡º")
    print("-" * 50)

    while True:
        topic = input("è¯·è¾“å…¥æŠ¥å‘Šä¸»é¢˜: ").strip()
        if topic.lower() in ["quit", "exit", "q"]:
            print("Goodbye! å†è§!")
            break

        if not topic:
            print("è¯·è¾“å…¥æœ‰æ•ˆçš„æŠ¥å‘Šä¸»é¢˜")
            continue

        print(f"\næ­£åœ¨ç”Ÿæˆå…³äº'{topic}'çš„æŠ¥å‘Š...")
        try:
            state = orchestrator_worker.invoke({"topic": topic})
            print(f"\næŠ¥å‘Šç”Ÿæˆå®Œæˆ! å…±ç”Ÿæˆ {len(state.get('completed_sections', []))} ä¸ªç« èŠ‚")
            print("\n" + "="*60)
            print("æœ€ç»ˆæŠ¥å‘Š:")
            print("="*60)
            print(state["final_report"])
            print("\n" + "="*60)
        except Exception as e:
            print(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºç°é”™è¯¯: {e}")
        print()

def main():
    """ä¸»å‡½æ•° - æä¾›å¤šç§åŠŸèƒ½é€‰æ‹©"""
    print("ğŸš€ LangGraph ç¼–æ’å·¥ä½œæµç¨‹å’ŒæŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ")
    print("=" * 60)

    while True:
        print("\nè¯·é€‰æ‹©åŠŸèƒ½:")
        print("1. æ¼”ç¤ºç¼–æ’å·¥ä½œæµç¨‹ (å•æ¬¡æŠ¥å‘Šç”Ÿæˆ)")
        print("2. äº¤äº’å¼æŠ¥å‘Šç”Ÿæˆå™¨ (è¿ç»­ç”ŸæˆæŠ¥å‘Š)")
        print("3. ç®€å•èŠå¤©æ¨¡å¼")
        print("4. é€€å‡º")

        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()

        if choice == "1":
            demo_orchestrator_workflow()
        elif choice == "2":
            interactive_report_generator()
        elif choice == "3":
            interactive_chat()
        elif choice == "4":
            print("æ„Ÿè°¢ä½¿ç”¨! å†è§!")
            break
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-4 ä¹‹é—´çš„æ•°å­—")

if __name__ == "__main__":
    main()
